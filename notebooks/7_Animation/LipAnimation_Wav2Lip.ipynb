{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LipAnimation_Wav2Lip.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevinash/awesome-ai/blob/main/notebooks/7_Animation/LipAnimation_Wav2Lip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSQFs_G8caeE"
      },
      "source": [
        "# Collab preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIVB0Xn1g6ih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40fc055c-4f26-4f30-fe6d-bc64f39c387a"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qciH4PsUazL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b38e7fa-ee12-4de4-ae4c-bcd29dfe6e13"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ5taGmPcWV-"
      },
      "source": [
        "# Get the code and models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3LihClHbUd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a540071-604c-4284-e16e-cbae8e3ac3d0"
      },
      "source": [
        "!git clone https://github.com/Rudrabha/Wav2Lip.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Wav2Lip'...\n",
            "remote: Enumerating objects: 326, done.\u001b[K\n",
            "remote: Total 326 (delta 0), reused 0 (delta 0), pack-reused 326\u001b[K\n",
            "Receiving objects: 100% (326/326), 503.95 KiB | 663.00 KiB/s, done.\n",
            "Resolving deltas: 100% (177/177), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-19nzx8SamJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e5e25a9-e409-45ac-f2b9-bdeee20a627c"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data  Wav2Lip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjzMPy_Sb0AI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f6eba1-7a00-41c0-8114-b61a8218c030"
      },
      "source": [
        "!cp -ri \"/content/gdrive/MyDrive/Wav2lip/wav2lip_gan.pth\" /content/Wav2Lip/checkpoints/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/gdrive/MyDrive/Wav2lip/wav2lip_gan.pth': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWTaOS3ncFt6"
      },
      "source": [
        "# Get the pre-requisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooh28vw-Uvd3"
      },
      "source": [
        "!pip uninstall tensorflow tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49dCYlLdcK2D"
      },
      "source": [
        "!cd Wav2Lip && pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey_bN4M6X_95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "40ea1940-5630-481f-8ce3-118908999d8b"
      },
      "source": [
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip/face_detection/detection/sfd/s3fd.pth\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-24 16:50:30--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n",
            "Resolving www.adrianbulat.com (www.adrianbulat.com)... 95.179.192.69\n",
            "Connecting to www.adrianbulat.com (www.adrianbulat.com)|95.179.192.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89843225 (86M) [application/octet-stream]\n",
            "Saving to: ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’\n",
            "\n",
            "Wav2Lip/face_detect 100%[===================>]  85.68M   499KB/s    in 2m 55s  \n",
            "\n",
            "2020-08-24 16:53:25 (502 KB/s) - ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdIQfY2Kswcb"
      },
      "source": [
        "# Now lets try!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoVGMtjRZfeR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a65ca468-7beb-45f7-c174-724c239d4475"
      },
      "source": [
        "!cp \"/content/gdrive/My Drive/Wav2Lip/input_vid.mp4\" \"/content/gdrive/My Drive/Wav2Lip/input_audio.wav\" sample_data/\n",
        "!ls sample_data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "anscombe.json\t\t      input_audio.wav  mnist_train_small.csv\n",
            "california_housing_test.csv   input_vid.mp4    README.md\n",
            "california_housing_train.csv  mnist_test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR5utmDMcSZY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b71b71d-dbe0-4469-e48d-b7221a1d6564"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/input_vid.mp4\" --audio \"../sample_data/input_audio.wav\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 185\n",
            "(80, 593)\n",
            "Length of mel chunks: 181\n",
            "  0% 0/2 [00:00<?, ?it/s]\n",
            "  0% 0/12 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 1/12 [00:16<03:01, 16.46s/it]\u001b[A\n",
            " 17% 2/12 [00:17<01:58, 11.88s/it]\u001b[A\n",
            " 25% 3/12 [00:18<01:18,  8.69s/it]\u001b[A\n",
            " 33% 4/12 [00:20<00:51,  6.43s/it]\u001b[A\n",
            " 42% 5/12 [00:21<00:33,  4.85s/it]\u001b[A\n",
            " 50% 6/12 [00:22<00:22,  3.76s/it]\u001b[A\n",
            " 58% 7/12 [00:23<00:14,  2.99s/it]\u001b[A\n",
            " 67% 8/12 [00:24<00:09,  2.46s/it]\u001b[A\n",
            " 75% 9/12 [00:26<00:06,  2.08s/it]\u001b[A\n",
            " 83% 10/12 [00:27<00:03,  1.81s/it]\u001b[A\n",
            " 92% 11/12 [00:28<00:01,  1.62s/it]\u001b[A\n",
            "100% 12/12 [00:36<00:00,  3.07s/it]\n",
            "Load checkpoint from: checkpoints/wav2lip_gan.pth\n",
            "Model loaded\n",
            "100% 2/2 [00:49<00:00, 24.83s/it]\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : stereo\n",
            "\u001b[0mInput #0, wav, from '../sample_data/input_audio.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.29.100\n",
            "  Duration: 00:00:07.40, bitrate: 1536 kb/s\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n",
            "Input #1, avi, from 'temp/result.avi':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.26.101\n",
            "  Duration: 00:00:07.24, start: 0.000000, bitrate: 937 kb/s\n",
            "    Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 600x480 [SAR 1:1 DAR 5:4], 931 kb/s, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0m\u001b[0;33m-qscale is ignored, -crf is recommended.\n",
            "\u001b[0m\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0mprofile High, level 3.0\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'results/result_voice.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p(progressive), 600x480 [SAR 1:1 DAR 5:4], q=-1--1, 25 fps, 12800 tbn, 25 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "    Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 128 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 aac\n",
            "frame=  181 fps= 61 q=-1.0 Lsize=     466kB time=00:00:07.40 bitrate= 515.4kbits/s speed= 2.5x    \n",
            "video:340kB audio:120kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.346917%\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0mframe I:1     Avg QP:17.11  size:  9276\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0mframe P:119   Avg QP:19.32  size:  2433\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0mframe B:61    Avg QP:22.73  size:   795\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0mconsecutive B-frames: 48.6% 15.5% 11.6% 24.3%\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0mmb I  I16..4: 50.4% 43.9%  5.7%\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0mmb P  I16..4:  1.9%  4.1%  0.2%  P16..4: 26.0%  7.5%  3.4%  0.0%  0.0%    skip:57.0%\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0mmb B  I16..4:  0.5%  1.6%  0.0%  B16..8: 26.2%  2.6%  0.2%  direct: 0.3%  skip:68.5%  L0:47.8% L1:46.3% BI: 5.9%\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0m8x8 transform intra:65.6% inter:76.0%\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0mcoded y,uvDC,uvAC intra: 32.1% 46.4% 4.1% inter: 6.9% 7.3% 0.0%\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0mi16 v,h,dc,p: 32% 34% 19% 14%\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 23% 42%  2%  1%  2%  1%  1%  2%\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 30% 23% 16%  3%  7%  9%  5%  5%  2%\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0mi8c dc,h,v,p: 46% 26% 25%  3%\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0mref P L0: 73.1% 11.3% 11.4%  4.1%\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0mref B L0: 86.8% 10.8%  2.3%\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0mref B L1: 97.3%  2.7%\n",
            "\u001b[1;36m[libx264 @ 0x55f21018a800] \u001b[0mkb/s:383.74\n",
            "\u001b[1;36m[aac @ 0x55f21025e000] \u001b[0mQavg: 574.082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNOAZvkszEOw"
      },
      "source": [
        "# use the \"files\" button on the left to download the result in the Wav2Lip/results/ folder."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7zgfrQqbKom"
      },
      "source": [
        "## **Variations to try**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f9A9VDVbZAG"
      },
      "source": [
        "1.   Use more padding to include the chin region"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45XW4SZAzIz5"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/input_vid.mp4\" --audio \"../sample_data/input_audio.wav\" --pads 0 20 0 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo-WnsxfbwTG"
      },
      "source": [
        "2.   Use resize_factor to reduce the video resolution, as there is a change you might get better results for lower resolution videos. Why? Because the model was trained on low resolution faces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw0xFtZ2bsx8"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/input_vid.mp4\" --audio \"../sample_data/input_audio.wav\" --resize_factor 2"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}